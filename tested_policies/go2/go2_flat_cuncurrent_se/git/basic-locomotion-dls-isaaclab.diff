--- git status ---
On branch devel
Your branch is up to date with 'origin/devel'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   deploy/config.py
	modified:   deploy/locomotion_policy_wrapper.py
	modified:   source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/agents/rsl_rl_ppo_cfg.py
	modified:   source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/go2_env_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	tested_policies/go2/go2_5asymm/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/deploy/config.py b/deploy/config.py
index f2e7540..d956747 100644
--- a/deploy/config.py
+++ b/deploy/config.py
@@ -4,7 +4,7 @@ dir_path = os.path.dirname(os.path.realpath(__file__))
 sys.path.append(dir_path+"/../")
 sys.path.append(dir_path+"/../scripts/rsl_rl")
 
-robot = 'aliengo'  # 'aliengo', 'go1', 'go2', 'b2', 'hyqreal1', 'hyqreal2', 'mini_cheetah' 
+robot = 'go2'  # 'aliengo', 'go1', 'go2', 'b2', 'hyqreal1', 'hyqreal2', 'mini_cheetah' 
 scene = 'random_boxes'  # flat, random_boxes, random_pyramids, perlin
 
 # ----------------------------------------------------------------------------------------------------------------
@@ -38,7 +38,7 @@ else:
 
 # ----------------------------------------------------------------------------------------------------------------
 
-policy_folder_path = dir_path + "/../tested_policies/" + robot + "/aliengo_symmetricactor"
+policy_folder_path = dir_path + "/../tested_policies/" + robot + "/go2_cuncurrent_se"
 #policy_folder_path = dir_path + "/../tested_policies/" + robot + "/go2_5asymm"
 
 cuncurrent_state_est_network = policy_folder_path + "/exported/cuncurrent_state_estimator.pth"
diff --git a/deploy/locomotion_policy_wrapper.py b/deploy/locomotion_policy_wrapper.py
index f64fec3..bb3eb56 100644
--- a/deploy/locomotion_policy_wrapper.py
+++ b/deploy/locomotion_policy_wrapper.py
@@ -87,6 +87,8 @@ class LocomotionPolicyWrapper:
         if(config.training_env["use_cuncurrent_state_est"] == True):
             self._cuncurrent_state_est_network = load_network(config.cuncurrent_state_est_network, device='cpu')
             self._observation_history_cuncurrent_state_est = np.zeros((self.history_length, single_observation_space), dtype=np.float32)
+            self._cuncurrent_state_est_filter = 0.9
+            self._past_base_lin_vel_predicted = np.zeros(3)
 
 
         # Desired joint vector
@@ -179,8 +181,10 @@ class LocomotionPolicyWrapper:
             obs_cuncurrent_state_est = self._observation_history_cuncurrent_state_est.flatten()
             # QUERY THE NETOWRK
             base_lin_vel_predicted = self._cuncurrent_state_est_network(torch.tensor(obs_cuncurrent_state_est, dtype=torch.float32).unsqueeze(0)).detach().numpy().squeeze()
-            obs[0:3] = base_lin_vel_predicted
-            
+            #obs[0:3] = base_lin_vel_predicted
+            obs[0:3] = base_lin_vel_predicted*self._cuncurrent_state_est_filter + (1-self._cuncurrent_state_est_filter)*self._past_base_lin_vel_predicted
+            self._past_base_lin_vel_predicted = copy.deepcopy(obs[0:3])
+
             
         if(self.use_observation_history):
             #the bottom element is the newest observation!!
diff --git a/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/agents/rsl_rl_ppo_cfg.py b/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/agents/rsl_rl_ppo_cfg.py
index cb55a8b..8fc520c 100644
--- a/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/agents/rsl_rl_ppo_cfg.py
+++ b/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/agents/rsl_rl_ppo_cfg.py
@@ -139,7 +139,7 @@ class RoughPPORunnerCfg(RslRlOnPolicyRunnerCfg):
         activation="elu",
     )
     algorithm = RslRlPpoAlgorithmCfg(
-        class_name="PPO", #PPO, PPOSymmDataAugmented #AMP_PPO
+        class_name="PPOSymmDataAugmented", #PPO, PPOSymmDataAugmented #AMP_PPO
         value_loss_coef=1.0,
         use_clipped_value_loss=True,
         clip_param=0.2,
diff --git a/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/go2_env_cfg.py b/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/go2_env_cfg.py
index 3d6bd4d..02ef1d6 100644
--- a/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/go2_env_cfg.py
+++ b/source/basic_locomotion_dls_isaaclab/basic_locomotion_dls_isaaclab/tasks/locomotion/go2_env_cfg.py
@@ -166,7 +166,7 @@ class Go2FlatEnvCfg(DirectRLEnvCfg):
         cuncurrent_state_est_batch_size = 512
         cuncurrent_state_est_train_epochs = 1000
         cuncurrent_state_est_lr = 1e-3
-        cuncurrent_state_est_ep_saving_interval = 1000
+        cuncurrent_state_est_ep_saving_interval = 500
 
     use_rma = False
     if(use_rma):